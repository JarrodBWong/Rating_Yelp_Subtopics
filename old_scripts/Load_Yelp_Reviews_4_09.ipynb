{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import urllib\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_reviews(theurl):\n",
    "    reviewInfo = {}\n",
    "    \n",
    "    stop =  stop = set(stopwords.words('english'))\n",
    "    \n",
    "    main_page = urllib.request.urlopen(theurl)\n",
    "    soup = BeautifulSoup(main_page, \"html.parser\")\n",
    "    \n",
    "    review_div = soup.findAll('div',{'itemprop':'review'})\n",
    "\n",
    "    reviewCount = 1\n",
    "    for i in review_div: # iterating through review_div \n",
    "        # get review star rating\n",
    "        reviewStar = float(i.find('meta',{'itemprop':'ratingValue'}).get('content', None))\n",
    "\n",
    "        # get review body text\n",
    "        reviewBody = i.find('p',{'itemprop':'description'})\n",
    "        for txt in reviewBody:\n",
    "            if type(txt) != '<p>' and not str(txt).startswith('<p>'):\n",
    "                reviewText = txt\n",
    "                \n",
    "                # Split review into sentences, remove stopwords, extract parts-of-speech tags\n",
    "                # (opt. if lots of reviews) store each review into MongoDB db called 'Reviews'\n",
    "\n",
    "                reviewWords = []\n",
    "                sentences = nltk.sent_tokenize(reviewText.lower())\n",
    "                \n",
    "                for sentence in sentences:\n",
    "                    tokens = nltk.word_tokenize(sentence)\n",
    "                    text = [w for w in tokens if w not in stop]\n",
    "                    tagged_text = nltk.pos_tag(text)\n",
    "                \n",
    "                for word, tag in tagged_text:\n",
    "                    reviewWords.append({'word': word, 'pos': tag})\n",
    "        \n",
    "        reviewInfo[reviewCount] = {'review_stars' : reviewStar, \\\n",
    "                                   'review_text' : reviewText, \\\n",
    "                                   'review_words' : reviewWords} \n",
    "        reviewCount += 1\n",
    "        \n",
    "    ## TODO: ITERATE THROUGH ALL PAGES OF REVIEWS FOR RESTAURANT ##\n",
    "        \n",
    "    return reviewInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lemmatize(reviewDict):\n",
    "    # loop through the reviews\n",
    "    # get nouns and group them by lemma\n",
    "    reviewCorpus = {}\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    for review_count, review_content in reviewDict.items():\n",
    "        nouns = []\n",
    "        words = [w for w in review_content['review_words'] if w['pos'] in ['NN','NNS']]\n",
    "        \n",
    "        for w in words:\n",
    "            nouns.append(lemmatizer.lemmatize(w['word']))\n",
    "            \n",
    "        reviewCorpus[review_count] = {'review_stars' : review_content['review_stars'], \\\n",
    "                                      'review_text' : review_content['review_text'], \\\n",
    "                                      'review_nouns' : nouns} \n",
    "    \n",
    "    return reviewCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed reviews to gensim LDA model\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import BleiCorpus\n",
    "from gensim import corpora\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test: First page of Pavement reviews\n",
    "first_page = 'https://www.yelp.com/biz/pavement-coffeehouse-boston'\n",
    "these_reviews = get_reviews(first_page)\n",
    "\n",
    "#print(these_reviews)\n",
    "#print(lemmatize(these_reviews))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
